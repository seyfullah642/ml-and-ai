{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "To compare performace of the classifiers `KNeighborsClassifier`, `LogisticRegression`, `DecisionTreeClassifier`, and `SVC`\n",
    "\n",
    "### Data\n",
    "\n",
    "Data used is a bank marketing dataset which comes from the UCI Machine Learning Repository.\n",
    "\n",
    "Note: I ran a ```python3.10 -m pip install ucimlrepo``` to retrieve the dataset, then imported it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_marketing = fetch_ucirepo(id=222)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of data and data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_tmp = pd.DataFrame(bank_marketing.data.features)\n",
    "bank_tmp['y'] = bank_marketing.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to remove columns `poutcome` and `contact` as they had quite a few missing values. I also believe that they would not have had an impact on the target as a feature. For the remaining `NaN's` I went ahead and removed those rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_tmp_drop = bank_tmp.drop(['poutcome', 'contact'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_data = bank_tmp_drop.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_cv(model, feature, target, parameters):\n",
    "    grid = GridSearchCV(estimator=model, param_grid=parameters).fit(feature, target)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(model_name, model, feature, target):\n",
    "    print(f'{model_name} results')\n",
    "    print(f'Training data score: {model.best_score_}')\n",
    "    print(f'Test data score: {model.score(feature, target)}')\n",
    "    print(f'Best parameters: {model.best_params_}')\n",
    "    print(f'Time for fitting best model: {model.refit_time_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrange data\n",
    "\n",
    "Since we have features that are of type object, I used `OneHotEncoder` on those features, and `StandardScaler` for types of float and int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bank_data.drop(['y'], axis=1)\n",
    "y = bank_data['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = make_column_transformer((OneHotEncoder(drop = 'if_binary'), ['job', 'marital', 'education', 'default', 'housing', 'loan', 'month']), \n",
    "                                     remainder = StandardScaler())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([('transform', transformer),\n",
    "                     ('knn', KNeighborsClassifier())]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kn_params = {'knn__n_neighbors': list(range(1,11))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid = grid_search_cv(knn_pipe, X_train, y_train, kn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores('KNeighborsClassifier', knn_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pipe = Pipeline([('transform', transformer),\n",
    "                     ('lr', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_params = {'lr__max_iter': list(range(1,11))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_grid = grid_search_cv(lr_pipe, X_train, y_train, lr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores('LogisticRegression', lr_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_pipe = Pipeline([('transform', transformer),\n",
    "                     ('dtr', DecisionTreeClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_params = {'dtr__criterion': ['gini', 'entropy', 'log_loss']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_grid = grid_search_cv(dtr_pipe, X_train, y_train, dtr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_scores('DecisionTreeClassifier', dtr_grid, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "\n",
    "I was unable to use GridSearchCV and pass a params_grid due to the limitations of my home computer. I have tried passing in two hyperparameters `kernel` and `gamma`, which led to the python kernel to run for more than an hour. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipe = Pipeline([('transform', transformer),\n",
    "                     ('svc', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SupportVectorMachines results')\n",
    "print(f'Training data score: {svc_pipe.score(X_train, y_train)}')\n",
    "print(f'Test data score: {svc_pipe.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {'model': ['KNN', 'Logistic Regression', 'DecisionTreeClassifier','SVC'],\n",
    "           'train score': [0.8916, 0.8951, 0.8719, 0.9129],\n",
    "           'test score': [0.8905, 0.8939, 0.8783, 0.8996],\n",
    "           'Best param fit time': [0.09899, 0.1378, 0.2204, 'NaN']}\n",
    "\n",
    "results_df = pd.DataFrame(res_dict).set_index('model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Despite not being able to get the best param fit time for the `SVC` classifer, I would say this is classifier performed best overall just by looking at the scores. I have a strong feeling that the fit time would be the lowest number as well.\n",
    "\n",
    "Note: I did not include any plots as the objective of this practial application assignment was to assess the best classifer.\n",
    "\n",
    "### Other Analysis\n",
    "\n",
    "If I did not have the CPU limitations on my computer, I could further my analysis by incorporating additional hyperparameters and cross-validation as well with `GridSearchCV`. Also, `GridSearchCV` has an attribute `cv_results_` that can be used to dive even deeper into the analysis of the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
